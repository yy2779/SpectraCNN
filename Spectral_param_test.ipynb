{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=1)\n",
    "# import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from modules.utils import load_cifar10\n",
    "# from modules.cnn_with_spectral_parameterization import CNN_Spectral_Param\n",
    "# from modules.cnn_with_spectral_pooling import CNN_Spectral_Pool\n",
    "from modules.image_generator import ImageGenerator\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "% matplotlib inline\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already downloaded..\n",
      "getting batch 1\n"
     ]
    }
   ],
   "source": [
    "# In the interest of training time, we only used 1 of 5 cifar10 batches\n",
    "# The important part of the experiment is to compare the rates of convergence of training accuracy,\n",
    "# so subsetting the training dataset for both spectral and spatial models shouldn't impact\n",
    "# the relationship between their train accuracy convergences\n",
    "xtrain, ytrain, xtest, ytest = load_cifar10(1, channels_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 32, 32, 3), (10000,), (10000, 32, 32, 3), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape, ytrain.shape, xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Rewrite tensorflow model to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generic_Net(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(generic_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size, padding=(kernel_size-1)//2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(96, 192, kernel_size, padding=(kernel_size-1)//2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(8*8*192, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 8 * 192)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  loss: 2.749  acc: 0.163 \n",
      "epoch: 2  loss: 2.645  acc: 0.210 \n",
      "epoch: 3  loss: 2.575  acc: 0.209 \n",
      "epoch: 4  loss: 2.837  acc: 0.176 \n",
      "epoch: 5  loss: 2.747  acc: 0.171 \n",
      "epoch: 6  loss: 2.645  acc: 0.178 \n",
      "epoch: 7  loss: 2.666  acc: 0.143 \n",
      "epoch: 8  loss: 2.645  acc: 0.132 \n",
      "epoch: 9  loss: 2.592  acc: 0.220 \n",
      "epoch: 10  loss: 2.503  acc: 0.271 \n",
      "epoch: 11  loss: 2.414  acc: 0.272 \n",
      "epoch: 12  loss: 2.512  acc: 0.257 \n",
      "epoch: 13  loss: 2.627  acc: 0.245 \n",
      "epoch: 14  loss: 2.762  acc: 0.196 \n",
      "epoch: 15  loss: 2.507  acc: 0.236 \n",
      "epoch: 16  loss: 2.519  acc: 0.251 \n",
      "epoch: 17  loss: 2.558  acc: 0.234 \n",
      "epoch: 18  loss: 2.563  acc: 0.226 \n",
      "epoch: 19  loss: 2.540  acc: 0.257 \n",
      "epoch: 20  loss: 2.495  acc: 0.276 \n"
     ]
    }
   ],
   "source": [
    "kernel_size = 3\n",
    "batch_size = 200\n",
    "learning_rate = 1e-5\n",
    "l2norm = 0.01\n",
    "total_epoch = 20\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net = generic_Net(kernel_size).cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    img_gen = ImageGenerator(xtrain, ytrain)\n",
    "    \n",
    "    generator = img_gen.next_batch_gen(batch_size)\n",
    "    iters = int(xtrain.shape[0] / batch_size)\n",
    "    \n",
    "    itr = 0\n",
    "    for epoch in range(total_epoch):\n",
    "        \n",
    "        loss_iter = []\n",
    "        acc_iter = []\n",
    "        for itr in range(iters):\n",
    "            itr += 1\n",
    "            \n",
    "            X_batch, y_batch = next(generator)\n",
    "            inputs = Variable(torch.Tensor(X_batch.transpose(0,3,1,2)).cuda())\n",
    "            labels = Variable(torch.LongTensor(y_batch).cuda())\n",
    "            \n",
    "            outputs = net.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            t = -1\n",
    "            for w in net.parameters():\n",
    "                t += 1\n",
    "                if t % 2 == 1: # because parameters contain both bias and weights, only need weights here\n",
    "                    continue\n",
    "                loss += w.norm(2) * l2norm\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predict = torch.max(outputs.data, 1)\n",
    "            \n",
    "            loss_iter.append(loss.data.cpu().numpy()[0])\n",
    "            acc_iter.append(predict.eq(labels.data).cpu().sum() / batch_size)\n",
    "        \n",
    "        ave_loss = np.mean(loss_iter)\n",
    "        ave_acc = np.mean(acc_iter)\n",
    "        print('epoch: %d  loss: %.3f  acc: %.3f ' % (epoch + 1, ave_loss, ave_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Spectral parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_fft.fft.autograd as fft\n",
    "\n",
    "class SpectralParam(Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(SpectralParam, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        \n",
    "        self.fft = fft.Fft2d()\n",
    "        \n",
    "        self.weight_re = nn.Parameter(torch.Tensor(out_channels, in_channels, kernel_size, kernel_size), requires_grad=True)\n",
    "        nn.init.xavier_uniform(self.weight_re)\n",
    "#         self.weight_im = nn.Parameter(torch.Tensor(out_channels, in_channels, kernel_size, kernel_size), requires_grad=True)\n",
    "#         nn.init.xavier_uniform(self.weight_im)\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_channels), requires_grad=True)\n",
    "            nn.init.normal(self.bias)\n",
    "        else:\n",
    "            self.bias = None\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "    def forward(self, input):\n",
    "#         weight, _ = self.fft(self.weight_re, self.weight_im)\n",
    "        weight, _ = self.fft(self.weight_re, torch.zeros_like(self.weight_re).cuda())\n",
    "        result = F.conv2d(input, weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "   4.6083   5.4162   6.2241\n",
      "   7.8398   8.6477   9.4556\n",
      "  11.0713  11.8792  12.6870\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "   5.4215   5.9661   6.5107\n",
      "   7.6000   8.1447   8.6893\n",
      "   9.7786  10.3232  10.8678\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "   0.4238   1.9521   3.4805\n",
      "   6.5372   8.0656   9.5940\n",
      "  12.6507  14.1791  15.7075\n",
      "[torch.cuda.FloatTensor of size 1x3x3x3 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  -0.6970  -7.8828  -5.4189 -10.4712\n",
      "  17.3574  30.4579  37.0283   8.3742\n",
      "  41.1802  56.7395  63.3100  10.8331\n",
      "  32.8472  61.3373  65.4439  27.0493\n",
      "[torch.cuda.FloatTensor of size 1x1x4x4 (GPU 0)]\n",
      " Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  5.3290e+03 -3.1132e+02\n",
      " -1.2453e+03 -1.2207e-04\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "  4.8425e+03 -2.9321e+02\n",
      " -1.1728e+03 -2.4414e-04\n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "  5.6026e+03 -2.9036e+02\n",
      " -1.1614e+03  1.2207e-04\n",
      "[torch.cuda.FloatTensor of size 3x1x2x2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = Variable(torch.arange(16).view(1, 1, 4, 4).cuda(), requires_grad=True)\n",
    "model = SpectralParam(1, 3, 2).cuda()\n",
    "\n",
    "B = model(A)\n",
    "print(B)\n",
    "C = torch.sum(B * B)\n",
    "C.backward()\n",
    "print(A.grad, model.weight_re.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generic_Net(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(generic_Net, self).__init__()\n",
    "        self.conv1 = SpectralParam(3, 96, kernel_size, padding=(kernel_size-1)//2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = SpectralParam(96, 192, kernel_size, padding=(kernel_size-1)//2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(8*8*192, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 8 * 192)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  loss: 2.889  acc: 0.107 \n",
      "epoch: 2  loss: 2.888  acc: 0.142 \n",
      "epoch: 3  loss: 2.850  acc: 0.133 \n",
      "epoch: 4  loss: 2.837  acc: 0.143 \n",
      "epoch: 5  loss: 2.792  acc: 0.143 \n",
      "epoch: 6  loss: 2.836  acc: 0.179 \n",
      "epoch: 7  loss: 2.747  acc: 0.167 \n",
      "epoch: 8  loss: 2.694  acc: 0.183 \n",
      "epoch: 9  loss: 2.648  acc: 0.209 \n",
      "epoch: 10  loss: 2.579  acc: 0.234 \n",
      "epoch: 11  loss: 2.518  acc: 0.272 \n",
      "epoch: 12  loss: 2.466  acc: 0.278 \n",
      "epoch: 13  loss: 2.413  acc: 0.309 \n",
      "epoch: 14  loss: 2.380  acc: 0.312 \n",
      "epoch: 15  loss: 2.391  acc: 0.312 \n",
      "epoch: 16  loss: 2.423  acc: 0.303 \n",
      "epoch: 17  loss: 2.342  acc: 0.329 \n",
      "epoch: 18  loss: 2.458  acc: 0.293 \n",
      "epoch: 19  loss: 2.329  acc: 0.331 \n",
      "epoch: 20  loss: 2.374  acc: 0.312 \n",
      "epoch: 21  loss: 2.275  acc: 0.376 \n",
      "epoch: 22  loss: 2.275  acc: 0.358 \n",
      "epoch: 23  loss: 2.254  acc: 0.370 \n",
      "epoch: 24  loss: 2.214  acc: 0.393 \n",
      "epoch: 25  loss: 2.257  acc: 0.380 \n",
      "epoch: 26  loss: 2.176  acc: 0.411 \n",
      "epoch: 27  loss: 2.209  acc: 0.404 \n",
      "epoch: 28  loss: 2.220  acc: 0.403 \n",
      "epoch: 29  loss: 2.166  acc: 0.422 \n",
      "epoch: 30  loss: 2.268  acc: 0.411 \n",
      "epoch: 31  loss: 2.158  acc: 0.426 \n",
      "epoch: 32  loss: 2.286  acc: 0.387 \n",
      "epoch: 33  loss: 2.185  acc: 0.424 \n",
      "epoch: 34  loss: 2.239  acc: 0.411 \n",
      "epoch: 35  loss: 2.186  acc: 0.434 \n",
      "epoch: 36  loss: 2.145  acc: 0.452 \n",
      "epoch: 37  loss: 2.138  acc: 0.456 \n",
      "epoch: 38  loss: 2.114  acc: 0.469 \n",
      "epoch: 39  loss: 2.101  acc: 0.469 \n",
      "epoch: 40  loss: 2.089  acc: 0.470 \n",
      "epoch: 41  loss: 2.045  acc: 0.495 \n",
      "epoch: 42  loss: 2.040  acc: 0.497 \n",
      "epoch: 43  loss: 2.033  acc: 0.502 \n",
      "epoch: 44  loss: 2.003  acc: 0.516 \n",
      "epoch: 45  loss: 2.010  acc: 0.520 \n",
      "epoch: 46  loss: 1.986  acc: 0.534 \n",
      "epoch: 47  loss: 1.971  acc: 0.542 \n",
      "epoch: 48  loss: 1.970  acc: 0.539 \n",
      "epoch: 49  loss: 1.948  acc: 0.554 \n",
      "epoch: 50  loss: 1.948  acc: 0.556 \n",
      "epoch: 51  loss: 1.936  acc: 0.565 \n",
      "epoch: 52  loss: 1.918  acc: 0.578 \n",
      "epoch: 53  loss: 1.923  acc: 0.573 \n",
      "epoch: 54  loss: 1.898  acc: 0.589 \n",
      "epoch: 55  loss: 1.910  acc: 0.591 \n",
      "epoch: 56  loss: 1.871  acc: 0.607 \n",
      "epoch: 57  loss: 1.902  acc: 0.596 \n",
      "epoch: 58  loss: 1.864  acc: 0.621 \n",
      "epoch: 59  loss: 1.922  acc: 0.605 \n",
      "epoch: 60  loss: 1.857  acc: 0.627 \n",
      "epoch: 61  loss: 1.882  acc: 0.617 \n",
      "epoch: 62  loss: 1.892  acc: 0.619 \n",
      "epoch: 63  loss: 1.851  acc: 0.643 \n",
      "epoch: 64  loss: 1.946  acc: 0.601 \n",
      "epoch: 65  loss: 1.851  acc: 0.641 \n",
      "epoch: 66  loss: 1.856  acc: 0.650 \n",
      "epoch: 67  loss: 1.882  acc: 0.640 \n",
      "epoch: 68  loss: 1.898  acc: 0.634 \n",
      "epoch: 69  loss: 1.807  acc: 0.678 \n",
      "epoch: 70  loss: 1.892  acc: 0.641 \n",
      "epoch: 71  loss: 1.868  acc: 0.653 \n",
      "epoch: 72  loss: 1.754  acc: 0.703 \n",
      "epoch: 73  loss: 1.819  acc: 0.678 \n",
      "epoch: 74  loss: 1.828  acc: 0.672 \n",
      "epoch: 75  loss: 1.783  acc: 0.702 \n",
      "epoch: 76  loss: 1.695  acc: 0.740 \n",
      "epoch: 77  loss: 1.785  acc: 0.710 \n",
      "epoch: 78  loss: 1.803  acc: 0.706 \n",
      "epoch: 79  loss: 1.674  acc: 0.758 \n",
      "epoch: 80  loss: 1.694  acc: 0.747 \n",
      "epoch: 81  loss: 1.741  acc: 0.729 \n",
      "epoch: 82  loss: 1.660  acc: 0.767 \n",
      "epoch: 83  loss: 1.661  acc: 0.772 \n",
      "epoch: 84  loss: 1.612  acc: 0.791 \n",
      "epoch: 85  loss: 1.604  acc: 0.796 \n",
      "epoch: 86  loss: 1.591  acc: 0.803 \n",
      "epoch: 87  loss: 1.515  acc: 0.838 \n",
      "epoch: 88  loss: 1.516  acc: 0.839 \n",
      "epoch: 89  loss: 1.513  acc: 0.838 \n",
      "epoch: 90  loss: 1.472  acc: 0.863 \n",
      "epoch: 91  loss: 1.470  acc: 0.864 \n",
      "epoch: 92  loss: 1.460  acc: 0.872 \n",
      "epoch: 93  loss: 1.435  acc: 0.884 \n",
      "epoch: 94  loss: 1.429  acc: 0.888 \n",
      "epoch: 95  loss: 1.409  acc: 0.898 \n",
      "epoch: 96  loss: 1.380  acc: 0.910 \n",
      "epoch: 97  loss: 1.371  acc: 0.916 \n",
      "epoch: 98  loss: 1.368  acc: 0.919 \n",
      "epoch: 99  loss: 1.330  acc: 0.938 \n",
      "epoch: 100  loss: 1.326  acc: 0.941 \n"
     ]
    }
   ],
   "source": [
    "kernel_size = 3\n",
    "batch_size = 200\n",
    "learning_rate = 1e-5\n",
    "l2norm = 0.01\n",
    "total_epoch = 100\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net = generic_Net(kernel_size).cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    img_gen = ImageGenerator(xtrain, ytrain)\n",
    "    \n",
    "    generator = img_gen.next_batch_gen(batch_size)\n",
    "    iters = int(xtrain.shape[0] / batch_size)\n",
    "    \n",
    "    itr = 0\n",
    "    for epoch in range(total_epoch):\n",
    "        \n",
    "        loss_iter = []\n",
    "        acc_iter = []\n",
    "        for itr in range(iters):\n",
    "            itr += 1\n",
    "            \n",
    "            X_batch, y_batch = next(generator)\n",
    "            inputs = Variable(torch.Tensor(X_batch.transpose(0,3,1,2)).cuda())\n",
    "            labels = Variable(torch.LongTensor(y_batch).cuda())\n",
    "            \n",
    "            outputs = net.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            t = -1\n",
    "            for w in net.parameters():\n",
    "                t += 1\n",
    "                if t % 2 == 1: # because parameters contain both bias and weights, only need weights here\n",
    "                    continue\n",
    "                loss += w.norm(2) * l2norm\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predict = torch.max(outputs.data, 1)\n",
    "            \n",
    "            loss_iter.append(loss.data.cpu().numpy()[0])\n",
    "            acc_iter.append(predict.eq(labels.data).cpu().sum() / batch_size)\n",
    "        \n",
    "        ave_loss = np.mean(loss_iter)\n",
    "        ave_acc = np.mean(acc_iter)\n",
    "        print('epoch: %d  loss: %.3f  acc: %.3f ' % (epoch + 1, ave_loss, ave_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
